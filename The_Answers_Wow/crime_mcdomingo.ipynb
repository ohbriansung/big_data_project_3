{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime over Time of Chicago\n",
    "\n",
    "In this .ipynb we analyze the change of crime over time in Chicago.\n",
    "\n",
    "Overall there has been a significant decrease in crime in Chicago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "First we need to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 ms, sys: 978 µs, total: 2.32 ms\n",
      "Wall time: 1.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# hdfs_port = \"hdfs://orion11:26990\"\n",
    "# hdfs_path = \"/FL_insurance_sample.csv\"\n",
    "\n",
    "hdfs_port = \"hdfs://orion11:13030\"\n",
    "hdfs_path = \"/crime-since-2001-chicago.csv\"\n",
    "df = spark.read.format('csv').option(\"header\", \"true\").load(hdfs_port + hdfs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'Case Number',\n",
       " 'Date',\n",
       " 'Block',\n",
       " 'IUCR',\n",
       " 'Primary Type',\n",
       " 'Description',\n",
       " 'Location Description',\n",
       " 'Arrest',\n",
       " 'Domestic',\n",
       " 'Beat',\n",
       " 'District',\n",
       " 'Ward',\n",
       " 'Community Area',\n",
       " 'FBI Code',\n",
       " 'X Coordinate',\n",
       " 'Y Coordinate',\n",
       " 'Year',\n",
       " 'Updated On',\n",
       " 'Latitude',\n",
       " 'Longitude',\n",
       " 'Location']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 02/10/2018 03:50:01 PM\n",
    "# from datetime import datetime\n",
    "# import time\n",
    "\n",
    "# time_format = '%m/%d/%Y %I:%M:%S %p'\n",
    "# time_str = \"02/10/2018 03:50:01 PM\"\n",
    "# time_object = time.strptime(time_str, time_format)\n",
    "# time_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning\n",
    "\n",
    "Here we use an SQL query to bin the data and select the features we want. We are binning by the lat/lon and counting the number of crimes that happen per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT ROUND(Latitude, 4) AS lat,\n",
      "    ROUND(Longitude, 4) AS lon,\n",
      "    COUNT(ID) AS count,\n",
      "    CAST(Year AS INT) AS year\n",
      "FROM crime_data\n",
      "WHERE Latitude is NOT NULL AND Longitude is NOT NULL\n",
      "GROUP BY lat, lon, year\n",
      "ORDER BY count DESC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dg = df\n",
    "\n",
    "dg.createOrReplaceTempView(\"crime_data\")\n",
    "\n",
    "query_str = f'''\n",
    "SELECT ROUND(Latitude, 4) AS lat,\n",
    "    ROUND(Longitude, 4) AS lon,\n",
    "    COUNT(ID) AS count,\n",
    "    CAST(Year AS INT) AS year\n",
    "FROM crime_data\n",
    "WHERE Latitude is NOT NULL AND Longitude is NOT NULL\n",
    "GROUP BY lat, lon, year\n",
    "ORDER BY count DESC\n",
    "'''\n",
    "\n",
    "print(query_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load into Pandas\n",
    "\n",
    "Here we apply the SQL query and load the results into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/site-packages/IPython/core/magics/execution.py\", line 1246, in time\n",
      "    exec(code, glob, local_ns)\n",
      "  File \"<timed exec>\", line 3, in <module>\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1968, in toPandas\n",
      "    pdf = pd.DataFrame.from_records(self.collect(), columns=self.columns)\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/site-packages/pandas/core/frame.py\", line 1269, in from_records\n",
      "    coerce_float=coerce_float)\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/site-packages/pandas/core/frame.py\", line 7475, in _to_arrays\n",
      "    dtype=dtype)\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/site-packages/pandas/core/frame.py\", line 7554, in _list_to_arrays\n",
      "    coerce_float=coerce_float)\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/site-packages/pandas/core/frame.py\", line 7621, in _convert_object_array\n",
      "    arrays = [convert(arr) for arr in content]\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/site-packages/pandas/core/frame.py\", line 7621, in <listcomp>\n",
      "    arrays = [convert(arr) for arr in content]\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/site-packages/pandas/core/frame.py\", line 7617, in convert\n",
      "    arr = lib.maybe_convert_objects(arr, try_float=coerce_float)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home4/mcdomingo/.conda/envs/py3/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dh = spark.sql(query_str)\n",
    "p_df = dh.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df['normcount']= (p_df['count']-p_df['count'].min())/(p_df['count'].max()-p_df['count'].min())\n",
    "maximum_count = p_df['count'].max()\n",
    "\n",
    "p_df['logcount'] = np.log(p_df['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting some constants\n",
    "\n",
    "Chicago Lat and Lon: 41.8781° N, 87.6298° W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_location = (41.8781, -87.6298)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2011 Data\n",
    "\n",
    "Crime seems to happen in 4 major areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "import folium.plugins as plugins\n",
    "\n",
    "m = folium.Map(location=chicago_location, zoom_start=10)\n",
    "\n",
    "data_list = p_df.loc[p_df['year'] == 2011][['lat', 'lon', 'normcount']].values\n",
    "\n",
    "hm = plugins.HeatMap(data_list, min_opacity=0.2, radius=7, max_zoom=1)\n",
    "\n",
    "m.add_child(hm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2013 Data\n",
    "\n",
    "Not much has changed since 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=chicago_location, zoom_start=10)\n",
    "\n",
    "data_list = p_df.loc[p_df['year'] == 2013][['lat', 'lon', 'normcount']].values\n",
    "\n",
    "hm = plugins.HeatMap(data_list, min_opacity=0.2, radius=7, max_zoom=1)\n",
    "\n",
    "m.add_child(hm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2015 Data\n",
    "\n",
    "There has been a significant decrease in crime in South Chicago, but Central Chicago still has some major problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=chicago_location, zoom_start=10)\n",
    "\n",
    "data_list = p_df.loc[p_df['year'] == 2015][['lat', 'lon', 'normcount']].values\n",
    "\n",
    "hm = plugins.HeatMap(data_list, min_opacity=0.2, radius=7, max_zoom=1)\n",
    "\n",
    "m.add_child(hm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 Data\n",
    "\n",
    "This data shows that crime has dramatically decreased in the South Chicago, so much so that is almost the same as the background.\n",
    "\n",
    "While considerably better, Central Chicago still holds some very dense pockets of crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=chicago_location, zoom_start=10)\n",
    "\n",
    "data_list = p_df.loc[p_df['year'] == 2018][['lat', 'lon', 'normcount']].values.tolist()\n",
    "\n",
    "hm = plugins.HeatMap(data_list, min_opacity=0.2, radius=7, max_zoom=1)\n",
    "\n",
    "m.add_child(hm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaway\n",
    "\n",
    "After studying this data, it appears that the police in Chicago are doing a great job in cleaning up crime. This is also due to the South Chicago gentrification that is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
