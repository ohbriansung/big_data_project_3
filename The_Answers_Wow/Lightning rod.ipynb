{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geohash2 as gh\n",
    "import gmaps\n",
    "import gmaps.datasets\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, LongType, StringType\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(Timestamp,LongType,true),StructField(Geohash,StringType,true),StructField(geopotential_height_lltw,FloatType,true),StructField(water_equiv_of_accum_snow_depth_surface,FloatType,true),StructField(drag_coefficient_surface,FloatType,true),StructField(sensible_heat_net_flux_surface,FloatType,true),StructField(categorical_ice_pellets_yes1_no0_surface,FloatType,true),StructField(visibility_surface,FloatType,true),StructField(number_of_soil_layers_in_root_zone_surface,FloatType,true),StructField(categorical_freezing_rain_yes1_no0_surface,FloatType,true),StructField(pressure_reduced_to_msl_msl,FloatType,true),StructField(upward_short_wave_rad_flux_surface,FloatType,true),StructField(relative_humidity_zerodegc_isotherm,FloatType,true),StructField(categorical_snow_yes1_no0_surface,FloatType,true),StructField(u-component_of_wind_tropopause,FloatType,true),StructField(surface_wind_gust_surface,FloatType,true),StructField(total_cloud_cover_entire_atmosphere,FloatType,true),StructField(upward_long_wave_rad_flux_surface,FloatType,true),StructField(land_cover_land1_sea0_surface,FloatType,true),StructField(vegitation_type_as_in_sib_surface,FloatType,true),StructField(v-component_of_wind_pblri,FloatType,true),StructField(albedo_surface,FloatType,true),StructField(lightning_surface,FloatType,true),StructField(ice_cover_ice1_no_ice0_surface,FloatType,true),StructField(convective_inhibition_surface,FloatType,true),StructField(pressure_surface,FloatType,true),StructField(transpiration_stress-onset_soil_moisture_surface,FloatType,true),StructField(soil_porosity_surface,FloatType,true),StructField(vegetation_surface,FloatType,true),StructField(categorical_rain_yes1_no0_surface,FloatType,true),StructField(downward_long_wave_rad_flux_surface,FloatType,true),StructField(planetary_boundary_layer_height_surface,FloatType,true),StructField(soil_type_as_in_zobler_surface,FloatType,true),StructField(geopotential_height_cloud_base,FloatType,true),StructField(friction_velocity_surface,FloatType,true),StructField(maximumcomposite_radar_reflectivity_entire_atmosphere,FloatType,true),StructField(plant_canopy_surface_water_surface,FloatType,true),StructField(v-component_of_wind_maximum_wind,FloatType,true),StructField(geopotential_height_zerodegc_isotherm,FloatType,true),StructField(mean_sea_level_pressure_nam_model_reduction_msl,FloatType,true),StructField(temperature_surface,FloatType,true),StructField(snow_cover_surface,FloatType,true),StructField(geopotential_height_surface,FloatType,true),StructField(convective_available_potential_energy_surface,FloatType,true),StructField(latent_heat_net_flux_surface,FloatType,true),StructField(surface_roughness_surface,FloatType,true),StructField(pressure_maximum_wind,FloatType,true),StructField(temperature_tropopause,FloatType,true),StructField(geopotential_height_pblri,FloatType,true),StructField(pressure_tropopause,FloatType,true),StructField(snow_depth_surface,FloatType,true),StructField(v-component_of_wind_tropopause,FloatType,true),StructField(downward_short_wave_rad_flux_surface,FloatType,true),StructField(u-component_of_wind_maximum_wind,FloatType,true),StructField(wilting_point_surface,FloatType,true),StructField(precipitable_water_entire_atmosphere,FloatType,true),StructField(u-component_of_wind_pblri,FloatType,true),StructField(direct_evaporation_cease_soil_moisture_surface,FloatType,true)))\n"
     ]
    }
   ],
   "source": [
    "feats = []\n",
    "f = open('../features.txt')\n",
    "for line_num, line in enumerate(f):\n",
    "    if line_num == 0:\n",
    "        # Timestamp\n",
    "        feats.append(StructField(line.strip(), LongType(), True))\n",
    "    elif line_num == 1:\n",
    "        # Geohash\n",
    "        feats.append(StructField(line.strip(), StringType(), True))\n",
    "    else:\n",
    "        # Other features\n",
    "        feats.append(StructField(line.strip(), FloatType(), True))\n",
    "    \n",
    "schema = StructType(feats)\n",
    "\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39 ms, sys: 12.9 ms, total: 51.9 ms\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = spark.read.format('csv').option('sep', '\\t').schema(schema).load('hdfs://orion11:30999/nam/data/nam_s')\n",
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+---------------------------------+\n",
      "|summary|  lightning_surface|categorical_rain_yes1_no0_surface|\n",
      "+-------+-------------------+---------------------------------+\n",
      "|  count|          108000000|                        108000000|\n",
      "|   mean|0.03493687962962963|              0.08852023148148148|\n",
      "| stddev|0.18361997272508837|               0.2840499970903469|\n",
      "|    min|                0.0|                              0.0|\n",
      "|    max|                1.0|                              1.0|\n",
      "+-------+-------------------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe([\n",
    "    'lightning_surface',\n",
    "    'categorical_rain_yes1_no0_surface'\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locations to get hit by lightning = 4\n",
      "CPU times: user 38.1 ms, sys: 14.4 ms, total: 52.5 ms\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.createOrReplaceTempView(\"nam_small\")\n",
    "lighting_location = spark.sql(\n",
    "    f'''SELECT * FROM(SELECT substr(Geohash,1,4) as geoloc, avg(lightning_surface) as lightavg, avg(categorical_rain_yes1_no0_surface) as avg_rain\n",
    "        FROM nam_small \n",
    "        GROUP BY substr(Geohash,1,4) \n",
    "        Having avg(lightning_surface) > .25) as t2\n",
    "    ORDER BY lightavg DESC\n",
    "    Limit 4\n",
    "    ''').collect()\n",
    "print(f'Locations to get hit by lightning = {len(lighting_location)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(geoloc='9g3v', lightavg=0.3184, avg_rain=0.392)\n",
      "Row(geoloc='9g3h', lightavg=0.29589905362776026, avg_rain=0.39621451104100947)\n",
      "Row(geoloc='9g3m', lightavg=0.29389942291838417, avg_rain=0.39159109645507006)\n",
      "Row(geoloc='9err', lightavg=0.275338530980714, avg_rain=0.34673779236766517)\n"
     ]
    }
   ],
   "source": [
    "for row in lighting_location:\n",
    "    print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9628e83e6f764b03bc0fef43dfc80943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lat_long_list = [[(19.25),(-98.61)],[(19.07),(-99.67)],[(19.25),(-99.32)],[(19.6),(-102.13)]]\n",
    "\n",
    "lighting = gmaps.symbol_layer(\n",
    "    lat_long_list,\n",
    "    fill_color='red',\n",
    "    stroke_color='red',\n",
    ")\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(lighting)\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Lightning\n",
    "\n",
    "From the map below you can see that most of the locations that you are likely to be struck by lightning are all in mexico. However after a quick google search it is shown that the places where there is the most lightning activity are in South America. This is likely because we restricting to parameters averaging all the lighting strikes within 4 geohash characters. I can expect that if we allowed for more than 4 geo hash characters I expect that these results will be significantly different.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locations to get hit by lightning = 4\n",
      "CPU times: user 82.6 ms, sys: 26 ms, total: 109 ms\n",
      "Wall time: 5min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.createOrReplaceTempView(\"nam_small\")\n",
    "lighting_location = spark.sql(\n",
    "    f'''SELECT * FROM(SELECT Geohash, avg(lightning_surface) as lightavg, avg(categorical_rain_yes1_no0_surface) as avg_rain\n",
    "        FROM nam_small \n",
    "        GROUP BY Geohash \n",
    "        Having avg(lightning_surface) > .25) as t2\n",
    "    ORDER BY lightavg DESC\n",
    "    Limit 4\n",
    "    ''').collect()\n",
    "print(f'Locations to get hit by lightning = {len(lighting_location)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Geohash='9g3h968ygj7z', lightavg=0.3969465648854962, avg_rain=0.5216284987277354)\n",
      "Row(Geohash='9g3m79nrf3zb', lightavg=0.36623376623376624, avg_rain=0.4675324675324675)\n",
      "Row(Geohash='9g3ug8ckk4hp', lightavg=0.3592964824120603, avg_rain=0.44221105527638194)\n",
      "Row(Geohash='9g3mq3f7y6eb', lightavg=0.3559718969555035, avg_rain=0.45433255269320844)\n"
     ]
    }
   ],
   "source": [
    "for row in lighting_location:\n",
    "    print (row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(19.087187, -99.787654),\n",
       " (19.210935, -99.329689),\n",
       " (19.121072, -98.63336),\n",
       " (19.214372, -99.214166)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_long_list = [gh.decode(row[0]) for row in lighting_location]\n",
    "lat_long_list = [(float(row[0]), float(row[1])) for row in lat_long_list]\n",
    "lat_long_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db7587c15f6454599259f34a36c18cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lighting = gmaps.symbol_layer(\n",
    "    lat_long_list,\n",
    "    fill_color='red',\n",
    "    stroke_color='red',\n",
    ")\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(lighting)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing, my hypothesis of allowing for more specific geohashes did not impact the locations. This is possible based on the test data itself ( maybe it does not include south america) or something to do with the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
