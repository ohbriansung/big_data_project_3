{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, LongType, StringType\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(Timestamp,LongType,true),StructField(Geohash,StringType,true),StructField(geopotential_height_lltw,FloatType,true),StructField(water_equiv_of_accum_snow_depth_surface,FloatType,true),StructField(drag_coefficient_surface,FloatType,true),StructField(sensible_heat_net_flux_surface,FloatType,true),StructField(categorical_ice_pellets_yes1_no0_surface,FloatType,true),StructField(visibility_surface,FloatType,true),StructField(number_of_soil_layers_in_root_zone_surface,FloatType,true),StructField(categorical_freezing_rain_yes1_no0_surface,FloatType,true),StructField(pressure_reduced_to_msl_msl,FloatType,true),StructField(upward_short_wave_rad_flux_surface,FloatType,true),StructField(relative_humidity_zerodegc_isotherm,FloatType,true),StructField(categorical_snow_yes1_no0_surface,FloatType,true),StructField(u-component_of_wind_tropopause,FloatType,true),StructField(surface_wind_gust_surface,FloatType,true),StructField(total_cloud_cover_entire_atmosphere,FloatType,true),StructField(upward_long_wave_rad_flux_surface,FloatType,true),StructField(land_cover_land1_sea0_surface,FloatType,true),StructField(vegitation_type_as_in_sib_surface,FloatType,true),StructField(v-component_of_wind_pblri,FloatType,true),StructField(albedo_surface,FloatType,true),StructField(lightning_surface,FloatType,true),StructField(ice_cover_ice1_no_ice0_surface,FloatType,true),StructField(convective_inhibition_surface,FloatType,true),StructField(pressure_surface,FloatType,true),StructField(transpiration_stress-onset_soil_moisture_surface,FloatType,true),StructField(soil_porosity_surface,FloatType,true),StructField(vegetation_surface,FloatType,true),StructField(categorical_rain_yes1_no0_surface,FloatType,true),StructField(downward_long_wave_rad_flux_surface,FloatType,true),StructField(planetary_boundary_layer_height_surface,FloatType,true),StructField(soil_type_as_in_zobler_surface,FloatType,true),StructField(geopotential_height_cloud_base,FloatType,true),StructField(friction_velocity_surface,FloatType,true),StructField(maximumcomposite_radar_reflectivity_entire_atmosphere,FloatType,true),StructField(plant_canopy_surface_water_surface,FloatType,true),StructField(v-component_of_wind_maximum_wind,FloatType,true),StructField(geopotential_height_zerodegc_isotherm,FloatType,true),StructField(mean_sea_level_pressure_nam_model_reduction_msl,FloatType,true),StructField(temperature_surface,FloatType,true),StructField(snow_cover_surface,FloatType,true),StructField(geopotential_height_surface,FloatType,true),StructField(convective_available_potential_energy_surface,FloatType,true),StructField(latent_heat_net_flux_surface,FloatType,true),StructField(surface_roughness_surface,FloatType,true),StructField(pressure_maximum_wind,FloatType,true),StructField(temperature_tropopause,FloatType,true),StructField(geopotential_height_pblri,FloatType,true),StructField(pressure_tropopause,FloatType,true),StructField(snow_depth_surface,FloatType,true),StructField(v-component_of_wind_tropopause,FloatType,true),StructField(downward_short_wave_rad_flux_surface,FloatType,true),StructField(u-component_of_wind_maximum_wind,FloatType,true),StructField(wilting_point_surface,FloatType,true),StructField(precipitable_water_entire_atmosphere,FloatType,true),StructField(u-component_of_wind_pblri,FloatType,true),StructField(direct_evaporation_cease_soil_moisture_surface,FloatType,true)))\n"
     ]
    }
   ],
   "source": [
    "feats = []\n",
    "f = open('../features.txt')\n",
    "for line_num, line in enumerate(f):\n",
    "    if line_num == 0:\n",
    "        # Timestamp\n",
    "        feats.append(StructField(line.strip(), LongType(), True))\n",
    "    elif line_num == 1:\n",
    "        # Geohash\n",
    "        feats.append(StructField(line.strip(), StringType(), True))\n",
    "    else:\n",
    "        # Other features\n",
    "        feats.append(StructField(line.strip(), FloatType(), True))\n",
    "    \n",
    "schema = StructType(feats)\n",
    "\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+\n",
      "|    Timestamp|temperature_surface|\n",
      "+-------------+-------------------+\n",
      "|1426377600000|          296.49802|\n",
      "|1426377600000|          254.49802|\n",
      "|1426377600000|          297.49802|\n",
      "+-------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "CPU times: user 27.9 ms, sys: 4.15 ms, total: 32 ms\n",
      "Wall time: 8.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = spark.read.format('csv').option('sep', '\\t').schema(schema).load('hdfs://orion11:13030/nam_tiny.tdv')\n",
    "df = df.select(['Timestamp', 'temperature_surface'])  # Select columns needed to speed up the process\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306.4980163574219"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_row = df.agg({'temperature_surface': 'max'}).collect()[0]\n",
    "hotest = max_row['max(temperature_surface)']\n",
    "hotest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Degrees Kelvin to Degrees Celsius converter for later use.\n",
    "def convert_dk_to_dc(dk):\n",
    "    return dk - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306.4980163574219 Degrees Kelvin = 33.3480163574219 Degrees Celsius\n"
     ]
    }
   ],
   "source": [
    "dc = convert_dk_to_dc(hotest)\n",
    "print(f'{hotest} Degrees Kelvin = {dc} Degrees Celsius')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hotest day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostest day count = 1\n",
      "Unix Timestamp = 1426377600.0\n",
      "Hostest date = 2015-03-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Creating an SQL 'table'\n",
    "df.createOrReplaceTempView(\"TINY_NAM\")\n",
    "\n",
    "# Getting the timestamp value of the highest temperature_surface row.\n",
    "hotest_time = spark.sql(f'SELECT Timestamp FROM TINY_NAM WHERE temperature_surface = {hotest}').collect()\n",
    "print(f'Hostest day count = {len(hotest_time)}')\n",
    "\n",
    "unix_timestamp = hotest_time[0]['Timestamp'] / 1000\n",
    "print(f'Unix Timestamp = {unix_timestamp}')\n",
    "\n",
    "hotest_date = datetime.utcfromtimestamp(unix_timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f'Hostest date = {hotest_date}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|temperature_surface|\n",
      "+-------+-------------------+\n",
      "|  count|                100|\n",
      "|   mean|  284.9017663574219|\n",
      "| stddev| 13.002025568205239|\n",
      "|    min|          247.49802|\n",
      "|    max|          306.49802|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['temperature_surface']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 284.9017663574219 Degrees Kelvin = 11.7517663574219 Degrees Celsius\n"
     ]
    }
   ],
   "source": [
    "_mean = 284.9017663574219\n",
    "_mean_dc = convert_dk_to_dc(_mean)\n",
    "print(f'Mean: {_mean} Degrees Kelvin = {_mean_dc} Degrees Celsius')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "pdf = df.toPandas()\n",
    "plt.figure(figsize=(6, 12))\n",
    "plt.boxplot(pdf['temperature_surface'].values)\n",
    "plt.yticks(np.arange(min(pdf['temperature_surface'].values)-1, max(pdf['temperature_surface'].values)+1, 3))\n",
    "plt.title(\"Temperature Box\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can observe that the highest temperature in the sample dataset is **306.5** Degrees Kelvin, which is 33.35 Degrees Celsius.\n",
    "* That happened on **March 15th, 2015** (UTC).\n",
    "* The result 306.5 is the max but not an outlier, so it's **not an anomaly** for the dataset.\n",
    "* I removed three tailing zeros from the Unix Timestamp since it was in millisecond format and we need second format to convert it into datetime in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 323759744 rows of data\n",
      "CPU times: user 161 ms, sys: 55.5 ms, total: 217 ms\n",
      "Wall time: 13min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = spark.read.format('csv').option('sep', '\\t').schema(schema).load('hdfs://orion11:13030/nam/*')\n",
    "print(f'Loaded {df.count()} rows of data')\n",
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest temperature = 331.390625\n",
      "331.390625 Degrees Kelvin = 58.24062500000002 Degrees Celsius\n",
      "Hostest day count = 1\n",
      "Unix Timestamp = 1440266400.0\n",
      "Hostest date = 2015-08-22 18:00:00\n",
      "+-------+-------------------+\n",
      "|summary|temperature_surface|\n",
      "+-------+-------------------+\n",
      "|  count|          323759744|\n",
      "|   mean|  287.8572105962259|\n",
      "| stddev| 13.716834080260098|\n",
      "|    min|          218.99284|\n",
      "|    max|          331.39062|\n",
      "+-------+-------------------+\n",
      "\n",
      "CPU times: user 205 ms, sys: 69 ms, total: 274 ms\n",
      "Wall time: 17min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Repeat the approach above\n",
    "max_row = df.agg({'temperature_surface': 'max'}).collect()[0]\n",
    "hotest = max_row['max(temperature_surface)']\n",
    "print(f'Highest temperature = {hotest}')\n",
    "\n",
    "dc = convert_dk_to_dc(hotest)\n",
    "print(f'{hotest} Degrees Kelvin = {dc} Degrees Celsius')\n",
    "\n",
    "df.createOrReplaceTempView(\"NAM\")\n",
    "hotest_time = spark.sql(f'SELECT Timestamp FROM NAM WHERE temperature_surface = {hotest}').collect()\n",
    "print(f'Hostest day count = {len(hotest_time)}')\n",
    "\n",
    "unix_timestamp = hotest_time[0]['Timestamp'] / 1000\n",
    "print(f'Unix Timestamp = {unix_timestamp}')\n",
    "\n",
    "hotest_date = datetime.utcfromtimestamp(unix_timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f'Hostest date = {hotest_date}')\n",
    "\n",
    "df.describe(['temperature_surface']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 287.8572105962259 Degrees Kelvin = 14.707210596225934 Degrees Celsius\n"
     ]
    }
   ],
   "source": [
    "_mean = 287.8572105962259\n",
    "_mean_dc = convert_dk_to_dc(_mean)\n",
    "print(f'Mean: {_mean} Degrees Kelvin = {_mean_dc} Degrees Celsius')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:43759)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 466, in collect\n",
      "    sock_info = self._jdf.collectToPython()\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o85.collectToPython\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:43759)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 466, in collect\n",
      "    sock_info = self._jdf.collectToPython()\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o85.collectToPython\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-563afffec32c>\", line 3, in <module>\n",
      "    pdf = df.toPandas()\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1968, in toPandas\n",
      "    pdf = pd.DataFrame.from_records(self.collect(), columns=self.columns)\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 466, in collect\n",
      "    sock_info = self._jdf.collectToPython()\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/traceback_utils.py\", line 78, in __exit__\n",
      "    self._context._jsc.setCallSite(None)\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:43759)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:43759)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 466, in collect\n",
      "    sock_info = self._jdf.collectToPython()\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o85.collectToPython\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-563afffec32c>\", line 3, in <module>\n",
      "    pdf = df.toPandas()\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 1968, in toPandas\n",
      "    pdf = pd.DataFrame.from_records(self.collect(), columns=self.columns)\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 466, in collect\n",
      "    sock_info = self._jdf.collectToPython()\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/traceback_utils.py\", line 78, in __exit__\n",
      "    self._context._jsc.setCallSite(None)\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:43759)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:43759)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 format(target_id, \".\", name))\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o85.collectToPython",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-563afffec32c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temperature_surface'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use as little memory as possible, OOM if using the entire dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temperature_surface'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1966\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_exception_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1968\u001b[0;31m             \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \"\"\"\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark-2.3.1-bin-hadoop2.7/python/pyspark/traceback_utils.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, tb)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    981\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \"\"\"\n\u001b[0;32m--> 983\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    936\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark-2.3.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:43759)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df = df.select(['temperature_surface'])  # Use as little memory as possible, OOM if using the entire dataset\n",
    "pdf = df.toPandas()\n",
    "plt.figure(figsize=(6, 12))\n",
    "plt.boxplot(pdf['temperature_surface'].values)\n",
    "plt.yticks(np.arange(min(pdf['temperature_surface'].values)-1, max(pdf['temperature_surface'].values)+1, 3))\n",
    "plt.title(\"Temperature Box\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The highest temperature of the entire dataset is **331.4** Degrees Kelvin, which is 58.24 Degrees Celsius.\n",
    "* The hotest date was **August 22, 2015** (UTC).\n",
    "* This is **an anomaly** since the temperature was way off the normal range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
